<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[从零开始写渲染引擎-开篇]]></title>
    <url>%2F2017%2F09%2F05%2F%EF%BC%88url%E4%B8%AD%E6%98%BE%E7%A4%BA%E7%9A%84%E6%A0%87%E9%A2%98%EF%BC%89%2F</url>
    <content type="text"><![CDATA[前言​ 最近 准备开始写一个自己的渲染引擎，主要有两个目的：一是为了系统的学习关于如何从底层开始写一个渲染引擎，二是为了以后方便给自己用；我会在博客和github上同步更新我的进度，博客的目的是为了把自己开发过程中的思路记录下来，同时也希望能找到志同道合之人一起学习进步，如果自己的经验能够给别人有点帮助那就最好不过了，同时所有的代码都会更新到github当中，如果有人能加入一起造轮子，那我会非常欢迎。 ​ 其实写之前也犹豫了很久，很多人可能会问，现在这么多开源的引擎，为什么不直接用呢，原因其实很简单，就像我之前讲过我对开源的理解，开源并不是说我们能用它做多少事情，而是我们能从开源当前学会多少东西。现在越来越少的人会去自己造轮子，都是直接用现成的东西，所以经常会遇到很多半桶水水平的人，这种人真多很烦，因为我是GIS专业的，而且也是在GIS公司，公司有些所谓的 老鸟，用过一些开源的引擎做了点东西，以为自己对图形学很熟悉了，可是经常连模板测试都一知半解的，然后还跟你争执，真是无语了，这让我更加意识到自己需要把基础打好，不能步其后尘。而造轮子是非常好的学习方法，很多东西真的需要自己动手去一个坑一个坑的跳，你才能对一些知识理解的更深入一点。就比方说学习编译原理最好的方法就是自己写个编译器。 ​ 我可能会先从OpenGL开始写起，后面会考虑慢慢更新WebGL版本，不过WebGL版本可能会倾向于数据可视化方面，因为这也是我想研究的一个方向，现在可能自己还需要学习一下，毕竟现在Web端也算是一个趋势了，不过两个版本如果用同一个架构的话，移植还是挺好的，所以，目前还是先把OpenGL版本写好吧！ ##SimpleRenderEngine V1.0框架设计 ​ 其实我写这篇博客的时候已经完成了一些基础的框架设计，主要是实现了一些基础类，比如Texture，Light，Camera，Entity，Scene，Mesh我等等。要说框架设计，好像没什么东西，就是先想一个简单的方法把它们串到一起，后面可能要慢慢重构吧，因为第一版本没考虑很高深的架构设计，但我写之前对自己引擎框架的要求就是，外部尽量简单，所以就需要里面能很好的连在一起，因为现在模块也比较少，所以把它们联系到一起很简单。先看下我这个引擎绘制一个cube外部代码大概向下面这样： 12345678910111213141516171819202122232425262728293031Win::Inst()-&gt;createWindow(); vector&lt;Vertex&gt; vertices;vertices.push_back(Vertex(0.5f, 0.5f, 0.0f, 0, 0, 1, 1, 1));vertices.push_back(Vertex(0.5f, -0.5f, 0.0f, 0, 0, 1, 1, 0));vertices.push_back(Vertex(-0.5f, -0.5f, 0.0f, 0, 0, 1, 0, 0));vertices.push_back(Vertex(-0.5f, 0.5f, 0.0f, 0, 0, 1, 0, 1));vector&lt;unsigned int&gt; indices = &#123; 0, 3, 1, 1, 3, 2 &#125;;Mesh::ptr mesh = std::make_shared&lt;Mesh&gt;();mesh-&gt;setVertices(vertices);mesh-&gt;setIndex(indices); mesh-&gt;createBuffer(); Light::ptr light = std::make_shared&lt;Light&gt;();light-&gt;setType(PointLight);TextureManager::Inst()-&gt;loadTexture("../../../src/Data/texture/1.jpg", "texture1");TextureManager::Inst()-&gt;loadTexture("../../../src/Data/texture/2.jpg", "texture2");TextureManager::Inst()-&gt;loadTexture("../../../src/Data/texture/3.jpg", "texture3");Camera::ptr camera = std::make_shared&lt;Camera&gt;(glm::vec3(0.0f, 0.0f, 3.0f));camera-&gt;setPerspectiveFovLHMatrix(glm::radians(45.0f), (float)SCR_WIDTH / (float)SCR_HEIGHT, 0.1f, 100.0f);Shader::ptr shader = std::make_shared&lt;Shader&gt;("../../../src/Data/shader/basic.vs", "../../../src/Data/shader/basic.fs"); mesh-&gt;setProgram(shader); mesh-&gt;addTexture("texture3");Scene::Inst()-&gt;addEntity("test", (Entity::ptr)mesh);Scene::Inst()-&gt;addLight(light);Win::Inst()-&gt;starup(camera); ​ 其实这个很简单，就是数据丢到mesh当中，纹理丢到textureManager中，然后建个camera，把mesh加到scene中，绘制，OK。具体内部怎么调用，大家可以到github把代码git下来看一下。 ​ 我可能不会在博客里将太多理论的东西，因为红宝书上都有，如果有个别不能理解的可以提问，可能后续会有些原理复杂一点的我会专门写篇博客去讲解，我会把思路，其实应该是框架性的东西，分享出来，当我写的过程中不知怎么办的时候，我也会写出来跟大家交流。我是个小白，所以也会有很多问题，希望能得到大牛的指点，也希望自己能坚持下去，只是因为喜欢。]]></content>
      <categories>
        <category>从零开始写渲染引擎</category>
      </categories>
      <tags>
        <tag>C++</tag>
        <tag>OpenGL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Earth开发原理-基于LRU-K实现瓦片数据析构算法]]></title>
    <url>%2F2017%2F09%2F02%2F%EF%BC%88url%E4%B8%AD%E6%98%BE%E7%A4%BA%E7%9A%84%E6%A0%87%E9%A2%98%EF%BC%89%2F</url>
    <content type="text"><![CDATA[​ 用户访问三维earth过程中，客户端会源源不断的向服务器请求数据，尤其是多用户并发的情况下，请求更加频繁，所以服务器通常会设置缓存容器，主要是DEM和DOM缓存池，数据从server中请求后，会在服务器同时保留一份。比如请求google 影像，服务器根据wtms服务地址以及用户请求的瓦片层级，然后利用HTTP协议将数据传输至服务器，这时候服务器就将数据进行备份，这样等下一次在请求同样的数据时，就可以直接从服务器中获取，这样可以提高用户访问效率。然而，随着用户访问的增加，服务器缓存压力必然也会加大，所以就需要及时析构一些数据，保证服务器缓存池不会爆。 LRU和LRU-K算法概述​ 缓存淘汰算法包括LRU、LFU和FIFO，关于这三种算法的比较，可以看一这篇博客： 缓存算法（页面置换算法）-FIFO、LFU、LRU ​ 这里只对LRU-K（LRU-K改进）算法作一个简单介绍，LRU或者LRU-K缓存析构算法是一种比较简单常用的缓存淘汰机制，LRU主要根据资源访问时间来淘汰数据，也就是说访问数据间隔越久，其淘汰顺序应该是月优先，所以在设计算法时，只需要设计一个队列来存储每个资源的访问时间，新访问的数据放到最前，这样就可以保证末尾的数据时间间隔最久，每次淘汰只需从末尾开始淘汰。 ​ 而LRU-K，则是增加了一个访问次数变量，通过访问次数K来控制需要淘汰的数据，所以它需要多维护一个队列来记录访问次数， 数据第一次被访问，加入到访问历史列表； 如果数据在访问历史列表里后没有达到K次访问，则按照一定规则（FIFO，LRU）淘汰； 当访问历史队列中的数据访问次数达到K次后，将数据索引从历史队列删除，将数据移到缓存队列中，并缓存此数据，缓存队列重新按照时间排序； 缓存数据队列中被再次访问后，重新排序； 需要淘汰数据时，淘汰缓存队列中排在末尾的数据，即：淘汰“倒数第K次访问离现在最久”的数据。 瓦片数据析构算法实现​ LRU-K淘汰机制可以很好的应用到瓦片数据的析构中，因为访问次数和时间两个权重可以通时考虑到用户访问的效率以及缓存池的压力，所以考虑将此方法应用到DEM和DOM缓冲析构当中，首先要考虑的是两个参数的确定，时间当然是指用户的访问某瓦片的时间，次数表示某瓦片被用户访问的次数，每个用户只会记录一次，这里需要对LRU-K作一个小小的改进，因为我们考虑析构的原则是：很久没被访问，且访问次数少的瓦片应该优先淘汰，所以需要把这两个权重都加入到用户访问记录中去。 ​ 综合考虑，析构算法主要思路是：当用户请求瓦片时，记录该瓦片的访问时间，并且增加瓦片访问次数（+1操作）。每次请求数据时，通过时间来更新访问次数，如果访问时间间隔大于给定的最大时间，则访问次数（-1操作）。通过+1和-1两个操作控制瓦片访问次数，当内存池容量超过一定阈值，需要执行析构时，从访问记录中取前K个访问次数较少的瓦片，释放其资源。 ​ LRU Node的设计如下： 1234567891011121314151617class lru_node &#123; friend class lru_queue; public: lru_node(); virtual ~lru_node(); public: void Hit(unsigned int time_now_); unsigned int get_time(); void bind_queue(lru_queue* queue_); void unbind_queue(); protected: unsigned int _last_use_time; lru_queue* _lru_queue; std::list&lt;lru_node*&gt;::iterator _self; &#125;; ​ 可以看出，这里只是设计了节点的访问时间，并且维护了一个队列，lru_queu的设计如下： 12345678910111213141516171819202122232425262728class lru_queue &#123; friend class lru_node; public: typedef gw_shared_ptr&lt;lru_queue&gt; ptr; public: lru_queue(runtime* run_time_, terrian_dem_resource_manager* dem_manager_); lru_queue(runtime* run_time_, terrian_dom_resource_manager* dom_manager_); ~lru_queue(); public: void move_top(lru_node* node_); void remove(lru_node* node_); unsigned int get_time(); lru_node* pop(); int get_queue_size(); void update(unsigned int lost_time_); protected: std::list&lt;lru_node* &gt; _list_queue; private: gw::mutex::ptr _queue_mutex; //union //&#123; enum Type&#123;DEM,DOM&#125;_type; terrian_dem_resource_manager* _dem_manager; terrian_dom_resource_manager* _dom_manager; //&#125;; &#125;; ​ 其中update函数就是通过时间来更新瓦片访问次数，就是从尾部遍历队列，如果访问时间与当前时间间隔大于lost_time，则只需-1操作。 ​ +1操作如下： 123456789101112131415161718192021222324252627void add_user_visit_record(std::string userid, geocode gc) &#123; lru_tile* node = new lru_tile(); node-&gt;_gc = gc; //dom_rm-&gt;_dom_list-&gt;move_top(node); unsigned int timt_now = get_tick_count(); node-&gt;Hit(timt_now); _queue_service-&gt;move_top(node, userid); _visit_record_mutex-&gt;lock(); std::vector&lt;RECORD_TYPE&gt;::iterator it = _visit_record_vec.begin(); for (; it != _visit_record_vec.end(); ++it) &#123; if (it-&gt;first == gc) &#123; it-&gt;second++; break; &#125; &#125; if (it == _visit_record_vec.end()) &#123; RECORD_TYPE record = std::make_pair(gc,1); _visit_record_vec.push_back(record); &#125; _visit_record_mutex-&gt;unlock(); &#125; 与之对应的-1操作如下： 1234567891011121314void visit_count_plus_one(geocode gc_)&#123; _visit_record_mutex-&gt;lock(); std::vector&lt;RECORD_TYPE&gt;::iterator it = _visit_record_vec.begin(); for (; it != _visit_record_vec.end(); ++it) &#123; if (it-&gt;first == gc_) &#123; it-&gt;second--; break; &#125; &#125; _visit_record_mutex-&gt;unlock();&#125; 总结​ 这个析构算法，虽然到现在并没有真正测试多用户并发情况下的效率，只是可以保证内存池能够稳定在阈值之内，可以到实际情况，还需要不断的优化和改进，因为数据加载效率也是非常重要的考量。]]></content>
      <categories>
        <category>Earth开发原理</category>
      </categories>
      <tags>
        <tag>C++</tag>
        <tag>服务器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Earth开发原理-阴影体实现要素贴地]]></title>
    <url>%2F2017%2F08%2F26%2F%EF%BC%88url%E4%B8%AD%E6%98%BE%E7%A4%BA%E7%9A%84%E6%A0%87%E9%A2%98%EF%BC%89%2F</url>
    <content type="text"><![CDATA[关于阴影实现方法概述​ Shadow map: 阴影的实现技术，我以前实现过比较基础的shadow map，就是利用从光源出发得到的深度图，然后每一个像素去比较当前深度值与深度图中的得到的深度值，深度图其实保存的应该是光源到遮光板之间的距离，而与它比较的是像素到光源的距离，如果小于，则说明处于阴影之中。还有一些细节的改进，比如阴影交叉如何处理（与深度图的分辨率有关，如果多个像素用同一个比较，就会出现这种情况），还有锯齿如何处理等等。 具体可以看这篇教程：Shadow map。 ​ Shadow volume: 上面这种方法会有两个问题：1.如果光源动态变化，则每一次shadow map都要更新，这样开销会很大；2.上述出现的交叉阴影和锯齿问题，都没有一种很好的方法完美解决。因此Franklin C. Crow在1977年 提出了一种新的方法：Shadow volume。不过这种方法好像对于多光源的情况下，也并无优势。所以现在主流的依然是shadow map方法，可以结合deferred lighting技术。不过因为今天的主题是要用到阴影体这种方法，所以下面线详细介绍一下这种方法。 Shadow volume实现方法​ shadow volume主要用到的原理是模板测试和深度测试，通过这两个测试，把阴影部分的stencil buffer计算出来，然后render这部分就可得到阴影。 ​ 第一步：构建阴影体。对mesh每一条边沿着光源方向进行拉伸，顶点部分除了原始的n个顶点(x,y,z,1)外，拉伸后的顶点同样也有n个，拉伸的长度应是无限远，但我们只有将其顶点形式设置为（x,y,z,0），在shader里面转换后自然就是无穷远处。面主要包括顶面、底面和侧面，底面三角形索引结构其实和顶面是一样的，侧面就是每一个quad由两个三角形组成，这样就可以得到阴影体的vertex buffer。 ​ 第二步：Render pass。 ​ pass1：打开depth test，按正常方式渲染整个场景，得到depth map。 ​ pass2：打开stencil test，关掉z writing和color buffer writing，渲染shadow volumes；设置stencil test always pass，对于front faces，若z test pass，则stencil value +1，若z test fail，则不更新stencil value；对于back faces，若z test pass，则stencil value -1。 ​ pass3：pass2完成之后，stencil buffer中value不为0的像素就处于阴影区域，据此绘制阴影效果即可。 12345678910111213141516//pass1RenderVolumetoDepth();//pass 2glDepthMask(GL_FALSE);glEnable(GL_DEPTH_CLAMP);glDisable(GL_CULL_FACE);glStencilFunc(GL_ALWAYS, 0, 0xff); glStencilOpSeparate(GL_BACK, GL_KEEP, GL_INCR_WRAP, GL_KEEP);glStencilOpSeparate(GL_FRONT, GL_KEEP, GL_DECR_WRAP, GL_KEEP);RenderVolume();//pass 3glStencilFunc(GL_EQUAL, 0x0, 0xFF); glStencilOpSeparate(GL_BACK, GL_KEEP, GL_KEEP, GL_KEEP);RenderVolume();glDisable(GL_STENCIL_TEST);...... ​ 这样就可以实现一个简单的阴影效果了，其中核心就是利用模板测试标记出阴影部分，当然还有一些细节，比如多光源的时候需要遍历每一个光源，想根深一步了解可以看《GPU Gems》Chapter 9. Efficient Shadow Volume Rendering. 利用阴影体实现贴地效果​ 前面简单的介绍了一下shadow volume的原理，下面要进入正题，要素贴地。这算是三维球中一个很基本的功能，因为这会涉及要标会，量测，矢量要素加载等等，所以这个问题也必须解决，才能有后续这些相关功能的实现。一开始对这个没什么概念，想了很多方法，第一反应到的就是纹理。在有DEM数据的情况下，面对高低起伏的地形，如何将要素随着地形起伏，感觉只有将其作为一张纹理贴地和瓦片数据一样贴到地形网格上，才能完美贴地，好像osgearth就是这样做的，所以就去研究投影纹理技术，投影纹理就不展开讲了，就类似虚拟一个投影仪，然后将纹理投影到物体表面。 ​ 阴影体这个方法是看了cesium的源码才知道原来贴地还可以这样，关于cesium后面应该还会有很多篇博客来讲其中的一些图形学知识，因为近期一直在研究它的源码，cesium算是web端的标杆了，类似pc端的oe，现在很多都在用它搞二次开发，比如超图。我们虽然没有直接用它，但是很多地方都在借鉴它的一些原理，其实我觉得这才是开源的意义，开源并不是让你可以直接用它进行二次开发，更主要的是你能够弄懂里面的一些原理，并为自己所用，这叫站在巨人的肩膀上。现在很多所谓的三维GIS创业公司，不过是做了点二次开发，包装了一个界面，就拿出来骗钱，非常可笑。不过也是，这几年政府的钱太好骗了，不过这样的没点技术积累的公司基本也存活不了多久。好了，不说废话了，开始装逼了。 ​ 前面说了阴影体怎么构建，那到了有DEM的情况下，又应该如何构建呢？比如说画一个Polygon，首先要做的就是拉伸，那拉伸又包括拉伸方向和拉伸高度，拉伸方向很简单就是顶点法线，拉伸高度应该与polygon所在地形高程与关，必须保持拉伸高度超过其范围之内的最大高程，所以拉伸高度就是高程的最大值。 ​ 阴影体构建之后，又如何只绘制贴地部分呢，这就要用到前面说的模板测试和深度测试了，这里有会有三个pass，不过这三个pass与前面的有点区别。 1234567891011121314151617181920212223242526272829//pass 1gl.colorMask(false,false,false,false);gl.depthMask(false);gl.enable(gl.STENCIL_TEST);gl.disable(gl.DEPTH_TEST);gl.disable(gl.CULL_FACE);gl.stencilFuncSeparate(gl.FRONT,gl.ALWAYS,0,~0);gl.stencilFuncSeparate(gl.BACK,gl.ALWAYS,0,~0);gl.stencilOpSeparate(gl.BACK,gl.KEEP,gl.DECR,gl.INCR_WRAP); gl.stencilOpSeparate(gl.FRONT,gl.KEEP,gl.DECR,gl.DECR_WRAP);renderShadowVolume(camera);//pass 2gl.enable(gl.DEPTH_TEST);gl.depthFunc(gl.LEQUAL);gl.stencilFuncSeparate(gl.FRONT,gl.ALWAYS,0,~0);gl.stencilFuncSeparate(gl.BACK,gl.ALWAYS,0,~0); gl.stencilOpSeparate(gl.BACK,gl.KEEP,gl.KEEP,gl.INCR_WRAP);gl.stencilOpSeparate(gl.FRONT,gl.KEEP,gl.KEEP,gl.DECR_WRAP);renderShadowVolume(camera);//pass 3gl.colorMask(true,true,true,true);gl.enable(gl.STENCIL_TEST);gl.enable(gl.BLEND);gl.disable(gl.DEPTH_TEST);gl.stencilFunc(gl.NOTEQUAL,0,~0);gl.stencilOp(gl.KEEP,gl.KEEP,gl.DECR);renderShadowVolume(camera);//set backgl.depthMask(true);gl.disable(gl.STENCIL_TEST); gl.enable(gl.CULL_FACE); gl.enable(gl.DEPTH_TEST); ​ pass 1：关闭颜色写入以及背面裁剪（因为是双面绘制，模板函数不一样），开启模板测试，关闭深度测试，正面模板值-1，背面模板值+1 ​ pass 2：开启深度测试和模板测试，同样正面-1，背面加+1 ​ pass 3：开启颜色写入，将模板值不为0的区域绘制出来，自然就是和地形相交的部分，就可以看到贴地效果。 ​ 这里有个很有意思的地方，就是只要pass 2和pass 3其实就可以标记出贴地部分，但如果你camera进入到阴影体区域，应该通过关闭深度测试来标记出把地形遮挡的区域，所以pass 1的目的其实是为了标记出进入阴影体内部的贴地区域，这两个标记需要分成两个pass，这样即使你进入阴影体内部也可以达到同样的效果。 总结​ 这算是我我开通博客站点后的第一篇博客，我就喜欢这种直接上干货的形式，毕竟这也是我想写博客的目的，积累和分享。同时也希望能保存博客的质量，只要是拿出来的，一定要有价值。这篇博客的分类是Earth开发原理，意味着以后我会陆续把我在开发三维earth过程中，一些有价值，有意思的技术分享出来，但我并不会直接把源码放出来，因为我分享的技术。也希望有看到的朋友多提建议，共同交流。 ​ 预告：下一篇可能会是google earth相机实现]]></content>
      <categories>
        <category>Earth开发原理</category>
      </categories>
      <tags>
        <tag>三维GIS</tag>
        <tag>图形算法</tag>
        <tag>WebGL</tag>
      </tags>
  </entry>
</search>
